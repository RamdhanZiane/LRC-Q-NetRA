{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'leidenalg', 'bayanpy', 'graph_tool', 'infomap'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw', 'pyclustering'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'leidenalg', 'wurlitzer', 'infomap'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import networkx as nx\n",
    "import json\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score, f1_score\n",
    "\n",
    "from train_ import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test_df\n",
    "tests_df = pd.DataFrame(columns=['graph', 'y_true', 'y_result','nmi', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('../data/football.gml')\n",
    "\n",
    "# Get the ground truth for communities\n",
    "y_football = [G.nodes[node]['value'] for node in G.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x19db3c4d5b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "url = \"http://www-personal.umich.edu/~mejn/netdata/football.zip\"\n",
    "\n",
    "sock = urllib.request.urlopen(url)  # open URL\n",
    "s = io.BytesIO(sock.read())  # read into BytesIO \"file\"\n",
    "sock.close()\n",
    "\n",
    "zf = zipfile.ZipFile(s)  # zipfile object\n",
    "txt = zf.read(\"football.txt\").decode()  # read info file\n",
    "gml = zf.read(\"football.gml\").decode()  # read gml data\n",
    "# throw away bogus first line with # from mejn files\n",
    "gml = gml.split(\"\\n\")[1:]\n",
    "G = nx.parse_gml(gml)  # parse gml data\n",
    "G = nx.convert_node_labels_to_integers(G, first_label=1, ordering=\"default\", label_attribute=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': '../data/karate.adjlist', 'outf': 'example', 'maxlen': 100, 'nhidden': 5, 'emsize': 30, 'nlayers': 1, 'noise_radius': 0.2, 'noise_anneal': 0.995, 'hidden_init': False, 'arch_g': '300-300', 'arch_d': '300-300', 'z_size': 100, 'temp': 1, 'enc_grad_norm': True, 'gan_toenc': -0.01, 'dropout': 0.0, 'epochs': 50, 'walk_length': 20, 'numWalks_per_node': 30, 'batch_size': 64, 'niters_ae': 1, 'niters_gan_d': 5, 'niters_gan_g': 1, 'niters_gan_schedule': '2-4-6-10-20-30-40', 'min_epochs': 6, 'no_earlystopping': False, 'lr_ae': 1, 'lr_gan_g': 5e-05, 'lr_gan_d': 1e-05, 'beta1': 0.9, 'clip': 1, 'gan_clamp': 0.01, 'sample': False, 'log_interval': 200, 'seed': 1111, 'cuda': False, 'ntokens': 115}\n",
      "e:\\CommunityDetectionModel\\LRC-Q-NetRA\\src\n",
      "middle point:\n",
      "0.8345999999999378\n",
      "probability of the middle point:\n",
      "0.07050841416353867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/train.txt\n",
      "Number of lines in total: 3450\n",
      "Vocabulary Size: 115\n",
      "Loaded data!\n",
      "Seq2Seq(\n",
      "  (embedding): Embedding(115, 30)\n",
      "  (embedding_decoder): Embedding(115, 30)\n",
      "  (encoder): LSTM(30, 5, batch_first=True)\n",
      "  (decoder): LSTM(35, 5, batch_first=True)\n",
      "  (linear): Linear(in_features=5, out_features=115, bias=True)\n",
      ")\n",
      "MLP_G(\n",
      "  (layer1): Linear(in_features=100, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (layer7): Linear(in_features=300, out_features=5, bias=True)\n",
      ")\n",
      "MLP_D(\n",
      "  (layer1): Linear(in_features=5, out_features=300, bias=True)\n",
      "  (activation1): LeakyReLU(negative_slope=0.2)\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): LeakyReLU(negative_slope=0.2)\n",
      "  (layer6): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "Training...\n",
      "loss tensor(4.7450, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7445, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7447, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7447, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7444, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7438, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7447, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7444, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7437, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7445, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7430, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7439, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7424, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7423, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7435, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7424, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7415, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7438, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7428, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7430, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7430, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7446, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7443, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7420, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7429, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7427, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7416, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7401, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7410, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7437, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7410, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7403, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7416, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7417, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7428, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7430, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7420, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7414, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7423, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7421, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7418, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7413, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7418, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7398, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7402, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7394, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7414, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 2\n",
      "loss tensor(4.7394, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7418, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7403, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7377, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7382, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7404, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7411, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7403, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7414, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7404, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7413, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7405, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7408, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7398, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7398, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7410, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7433, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7382, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7412, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7397, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7425, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7403, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7409, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7392, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7429, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7404, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7404, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7388, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7432, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 3\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7382, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7420, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7422, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7388, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7381, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7397, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7415, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7409, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7426, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7391, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7381, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7377, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7410, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7392, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7388, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 4\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7391, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7392, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7377, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7411, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7404, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7409, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7443, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7420, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7388, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7381, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7399, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7397, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7452, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7385, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7243, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7402, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7396, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7418, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7409, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7257, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7269, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7429, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7368, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7388, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 5\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7368, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7368, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7408, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7448, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7403, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7248, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7425, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7431, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7298, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7298, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7409, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7250, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7396, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7387, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7278, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7413, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7387, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7391, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7398, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7377, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7281, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7419, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7401, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7245, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7234, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7264, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7368, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7263, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7385, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7392, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7405, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7254, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7394, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7411, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7255, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7261, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7381, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7269, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7377, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7259, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7388, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7256, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7246, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7298, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7396, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7402, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7290, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7256, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7362, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7245, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7428, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7247, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7376, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7264, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7402, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7417, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7254, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7265, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7278, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7256, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7378, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7269, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7406, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7372, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7278, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7254, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7396, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7290, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7401, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 6\n",
      "loss tensor(4.7342, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7298, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7281, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7385, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7356, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7242, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7351, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7249, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7385, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7262, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7290, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7248, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7405, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7360, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7368, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7354, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7277, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7268, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7278, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7375, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7223, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7236, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7260, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7268, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7266, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7413, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7268, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7251, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7254, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7290, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7271, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7241, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7298, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7251, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7269, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7245, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7261, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7339, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7270, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7281, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7235, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7261, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7277, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7237, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7322, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7215, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7304, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7332, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7278, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7256, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7317, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7266, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7251, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7254, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7334, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7301, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7265, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7268, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7265, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7381, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7281, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7242, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7259, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7266, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7261, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7241, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7215, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7278, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7335, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7226, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7245, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7276, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7221, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7275, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7237, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7202, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7274, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7218, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7318, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7277, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7274, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7223, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7249, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7246, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7239, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7252, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7242, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7271, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7265, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7232, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7257, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7274, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7246, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7229, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7225, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7274, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7239, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7243, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7270, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7270, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7186, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7338, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7305, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7269, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7267, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7263, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7247, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7252, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7271, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7219, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7234, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7219, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7202, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7281, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7235, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7236, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7250, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7233, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7243, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7306, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7215, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7227, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7243, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7259, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7221, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7208, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7169, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7371, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7274, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7138, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7138, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7270, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7215, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7211, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7229, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7257, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7170, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7213, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7179, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7255, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7239, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7175, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7216, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7189, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7175, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7205, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7215, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7240, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7274, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7241, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7228, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7136, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7193, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7169, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7197, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7200, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7175, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7178, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7181, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7196, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7158, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7183, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7133, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7148, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7239, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7205, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7222, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7220, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7226, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7170, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7150, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7185, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7121, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7253, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7133, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7120, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7150, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7061, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7162, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7105, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7111, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7097, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7124, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7133, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7171, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7182, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7075, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7056, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7138, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7160, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7143, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7085, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7040, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7100, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7180, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7036, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7127, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7028, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7073, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6840, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6988, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7104, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7005, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7007, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6977, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6936, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7131, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7259, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7187, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7225, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7031, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7001, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6949, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6882, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6955, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6972, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7050, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7047, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6998, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6884, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6898, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6813, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 7\n",
      "loss tensor(4.7018, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7439, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7095, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6957, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7205, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6964, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6877, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6988, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6839, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6815, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6793, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6810, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6997, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7237, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7209, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6796, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6638, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6654, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6575, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6577, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6785, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6729, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6970, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6920, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7529, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7516, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7090, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6909, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6600, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6453, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6540, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6476, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6648, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6661, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7029, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6762, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6588, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7192, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6325, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6529, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6872, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6519, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6899, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6497, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6606, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6054, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6160, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6083, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6426, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6037, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6041, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5845, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5867, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5908, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5706, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5848, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5821, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6167, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6581, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.7197, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5953, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5859, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6197, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.6032, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5824, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5554, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5597, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5457, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5674, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5424, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5277, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5162, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5134, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5191, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5007, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5079, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5105, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5153, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5009, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4874, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4898, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4985, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4774, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4906, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4957, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.5002, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4445, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4773, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4710, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4759, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4518, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4621, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4583, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4480, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4211, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4255, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4062, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4386, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4117, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4058, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4165, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4094, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4175, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4116, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4024, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3847, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3716, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3984, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3972, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3674, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3833, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3964, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3748, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3709, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3705, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3625, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3917, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3601, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3551, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3483, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3556, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3825, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3677, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3644, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3331, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3487, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3515, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3184, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3174, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3383, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3307, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3220, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3095, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3003, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2932, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3189, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3070, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3065, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3056, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2907, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2841, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2882, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2966, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2981, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2673, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.3032, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2763, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2859, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2918, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2810, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2766, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2682, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2669, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2559, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2772, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2671, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2495, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2576, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2681, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2754, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.4921, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2548, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2477, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2479, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2523, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2547, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2395, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2425, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2268, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2411, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2255, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2206, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2162, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2248, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2239, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2326, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2070, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2385, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2113, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2223, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2266, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2048, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2312, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2022, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1950, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2164, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2180, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.2063, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1927, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1927, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1924, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1916, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1868, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1776, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1958, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1699, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1545, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1960, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1587, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1694, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1551, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1864, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1608, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1874, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1626, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1845, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1735, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1507, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1726, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1492, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1592, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1583, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1610, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1568, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1664, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1516, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1535, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1495, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1490, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1417, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1545, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1227, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1389, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1099, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1482, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1466, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1128, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1158, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1251, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1180, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0904, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1066, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0996, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1250, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1095, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0981, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1079, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1181, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1106, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0930, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.1028, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0927, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0973, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0874, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0971, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0818, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0712, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0787, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0778, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0801, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0829, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0575, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0978, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0534, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0980, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0770, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0725, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0622, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0837, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0670, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0699, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0594, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0473, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0842, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0712, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0806, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0651, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0444, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0377, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0227, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0418, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0566, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0400, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0049, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0471, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0572, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0350, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0280, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0352, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0279, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0253, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0458, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0122, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0296, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0244, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0292, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9966, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9933, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0206, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9930, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9826, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0249, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0000, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0228, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9819, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0192, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9671, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9860, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9910, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9766, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9953, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0108, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9779, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9736, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9558, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9664, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9906, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0078, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9926, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9928, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9806, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(4.0096, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9834, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9695, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9683, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9363, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9827, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9672, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9613, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9654, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9522, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9811, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9685, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9494, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9552, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9734, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9673, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9438, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9634, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9236, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9581, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9528, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9666, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9059, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9419, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9072, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9259, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9054, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9121, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9410, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9133, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9469, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9069, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9018, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9245, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8926, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9463, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9341, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8879, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8796, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9078, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9104, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8961, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9171, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8900, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9094, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8869, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9101, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9155, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9056, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8919, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8986, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8788, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8769, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9093, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.9054, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8748, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8835, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8784, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8757, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8582, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8359, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8575, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8770, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8871, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8430, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8702, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8531, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8366, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8685, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8282, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8744, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8556, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8682, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7896, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8605, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8209, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8669, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8353, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8158, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8044, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7973, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7826, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7899, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8365, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8017, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8082, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7997, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8127, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8155, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7991, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8199, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8079, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8092, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8172, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8200, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8050, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7983, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.8140, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7649, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7549, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7984, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7769, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7481, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7762, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7846, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7947, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7597, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7492, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7423, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7501, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7391, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7173, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7847, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7199, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7503, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7027, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7699, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7085, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7047, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7406, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6980, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7130, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6982, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7374, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6833, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6798, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6621, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6860, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6923, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6821, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.7088, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6998, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6899, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6559, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6753, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6951, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6812, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6695, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6436, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6512, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6586, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6295, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6444, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6714, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6666, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6463, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6091, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6011, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6636, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6508, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6180, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5938, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5867, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6218, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6214, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6425, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6008, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5814, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5909, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6154, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5910, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6109, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5979, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6203, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5948, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5719, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.6152, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5745, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5896, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5856, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5937, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5781, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5471, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5552, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5242, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5409, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5629, grad_fn=<NllLossBackward0>)\n",
      "GAN training loop schedule increased to 8\n",
      "loss tensor(3.5311, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5433, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5447, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5446, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5344, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5340, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5387, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4891, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5099, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4791, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4989, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4989, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4952, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4673, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5131, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4785, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4946, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4724, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4690, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4778, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.5104, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4834, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4798, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4828, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4727, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4669, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4448, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4533, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4859, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4530, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4314, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4256, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4145, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3966, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4431, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4216, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4214, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4145, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3846, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.4071, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3916, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3724, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3801, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3741, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3542, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3711, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3297, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3817, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3576, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3730, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3442, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3932, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3320, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3576, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3346, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3616, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3397, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3215, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3398, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3078, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2996, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.3112, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2686, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2903, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2575, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2923, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2663, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2874, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2763, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2929, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2632, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2591, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2660, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2991, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2875, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2880, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2514, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2381, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2826, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2521, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1917, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2379, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2565, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2252, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2347, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2109, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2223, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2225, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2294, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2204, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2217, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1830, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2224, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.2018, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1918, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1912, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1754, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1857, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1717, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1810, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1596, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1440, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1772, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1643, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1607, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1556, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1640, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1218, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1531, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1543, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1209, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1256, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1213, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0946, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1196, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1040, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1205, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1358, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0589, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1041, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1158, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0719, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0799, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1182, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1057, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0864, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1373, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.1149, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0571, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0643, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0422, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0437, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0616, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0906, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0868, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0544, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0511, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0283, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0551, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0493, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0336, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0446, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0536, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0097, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0475, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0186, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0655, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0105, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0235, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9882, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0108, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9787, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0082, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9831, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9804, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9715, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9908, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9795, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9919, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9993, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(3.0057, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9878, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9616, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9901, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9733, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9893, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9684, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9808, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9827, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9638, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9620, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9431, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9553, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9137, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9466, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9557, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9673, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9424, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9393, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9511, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8884, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9391, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9146, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9178, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9228, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9224, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9302, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9166, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8916, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9505, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9043, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9094, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9022, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8891, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9073, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9138, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9238, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8745, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8584, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9082, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9075, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8828, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9038, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8785, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.9193, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8477, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8846, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8820, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8546, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8870, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8779, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8423, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8608, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8728, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8600, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8396, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8367, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8263, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8438, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8528, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8552, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8942, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8117, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8402, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8101, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8405, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8643, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8136, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8591, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8031, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8210, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8293, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8085, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8380, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7942, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8333, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8161, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7993, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8290, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7916, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8146, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8134, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8101, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8193, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7893, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7870, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7966, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7738, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7651, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7975, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7860, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7704, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8126, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7765, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7718, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7888, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7728, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.8116, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7493, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7618, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7719, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7714, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7551, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7357, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7345, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7476, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7411, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7444, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7407, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7419, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7382, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7533, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7364, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7330, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7775, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7476, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7645, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7619, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7486, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7172, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6965, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6843, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7289, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7209, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6862, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7204, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6851, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7369, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7284, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7480, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6996, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6807, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7090, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7076, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7232, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6901, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7003, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6769, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6735, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7041, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.7228, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6782, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6973, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6720, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6527, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6834, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6729, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6531, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6612, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6658, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6313, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6592, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6647, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6456, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6198, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6089, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6580, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6644, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6618, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6575, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6019, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6250, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6163, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6173, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6240, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6229, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6118, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6169, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6191, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5892, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5742, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6126, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5854, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6400, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6041, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6161, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5758, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5670, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5735, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6323, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5696, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5632, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5780, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5729, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5198, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5642, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.6268, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5681, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5420, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5260, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5508, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5189, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5414, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5112, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5343, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5497, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4952, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5233, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4788, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5017, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5186, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4916, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5533, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5158, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4938, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4786, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5041, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4913, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5098, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.5299, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4844, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4808, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4891, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4686, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4863, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4753, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4587, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4300, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4836, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4698, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4474, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4832, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4461, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4851, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4370, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4621, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4748, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4564, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4679, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4337, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4406, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4315, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4101, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4951, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4034, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4310, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4253, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4432, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4148, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4319, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4027, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4093, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3966, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4160, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4049, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3885, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3711, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3794, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3706, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3922, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3912, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3994, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3951, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4025, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4191, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3725, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.4102, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3854, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3750, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3661, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3643, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3702, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3451, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3612, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3444, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3726, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3649, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3640, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3396, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2915, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3589, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3620, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3660, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3349, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3219, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3669, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3266, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3573, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3534, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3051, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3471, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3121, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3446, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2846, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3260, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3427, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3411, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3286, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2841, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3288, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2962, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2926, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2758, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3004, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2727, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2660, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3324, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2808, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2891, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2973, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2732, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2743, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2414, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.3308, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2867, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2855, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2580, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2639, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2689, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2410, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2872, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2895, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2515, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2740, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2361, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2632, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2737, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2730, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2568, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2851, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2316, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2441, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2327, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2574, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2630, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2660, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2272, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2157, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2784, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2241, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2287, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2478, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1985, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2020, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1930, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2254, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2348, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2231, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2585, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2355, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2156, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2100, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2092, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1882, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2027, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1895, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1729, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2058, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2328, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1648, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1976, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1582, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2225, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2089, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1977, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1744, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1709, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1802, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1530, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2054, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2285, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1724, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2026, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1819, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1321, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1947, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1918, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1309, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.2097, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1768, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1597, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1291, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1758, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1570, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1638, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1653, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1700, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1838, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1749, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1431, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1664, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1303, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1153, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1329, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1262, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1390, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1023, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1506, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.0978, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1422, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1273, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.0992, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1199, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1384, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1010, grad_fn=<NllLossBackward0>)\n",
      "loss tensor(2.1228, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABR1ElEQVR4nO3de3hU5bn///dMZibJ5DA5QBISDEKiErVYESmtbFsERdRai8qhW7cHQK21VdmtqK1tsWwV929X26/bVgGFauWgtra2Khq1rVgPu+KhKEgTkQgIgYQcJ8nMZNbvj0VCDjPJTDIzyWQ+r+vKRTJrrSdPFLLuedb93LfFMAwDERERSVjWoZ6AiIiIDC0FAyIiIglOwYCIiEiCUzAgIiKS4BQMiIiIJDgFAyIiIglOwYCIiEiCCykYMAyDhoYGVJJARERk5AkpGGhsbMTlctHY2Bjt+YiIiEiM6TGBiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuBsQz0BERGRhFJ3EHZ9AO5GcGbA+EmQNXpIp6RgQEREJNrcjfD8anh+FVRt7328uAzmLIE5i80AIcYsRghlBRsaGnC5XNTX15OZmRmLeYmIiIwMW8vh54uguqr/c/OKYekamDwr+vPqQjkDIiIi0fLCI3D77NACATDPu302bH40uvPqQcGAiIhINGwth/uXgN8f3nV+P9y32Lw+RhQMiIiIRJq70Xw0ECAQ8Prhhh2Q/SrkvArf3QG+nqf5/eb17tj0BFIwICIiEmnPrw76aGDFLthyGD76Cnz4FXjtMNy1K8CJ1VXwwprozvMIBQMiIiKR9vyqoIce2Qs/mgBjks2PH06ANfuCnPzcw9GZXw8KBkRERCKp7mDg7YPAYS/saYMvdtk9+MV0qGqFem+AC6q2Q/2h6MyzCwUDIiIikbTrg6CHmtrNP7O6VPnJspt/NrYHueiT9yMzrz4oGBAREYmkPpL+0pPMP+t9R1/r+DwjKchFLU2RmVcfFAyIiIhEUh8VBLPtMDYZ3usSL7zXCMekgMse5KLU9MjOLwAFAyIiIpE0flKfh68qhP/aBfvbzI+7dsHiwj4umHBKZOcXgHoTiIiIRFLWaLPXQJAkwjsmQI0Xyv5ufn3ZGLh9fJCxisvANSo68+xCKwMiIiKRNmdJ0EN2K/xvGRyeYX78v4lgC3Y3Pu+a6MyvBwUDIiIikTZnsdl0aDDyiuHcRZGZTz8UDIiIiESaM8PsPmgd4G3WajWvj1E7YwUDIiIi0TB5Fty0KvyAwGqFm1fHtI2xggEREZFoOfdquGtz6I8M8orN82dfFd159WAxDMPo76SGhgZcLhf19fVkZmbGYl4iIiIjh7vRbDr03MOBdxkUl5nJgucuitmjga4UDIiIiMRS3UGzZHFLk1lQaMIpMdk+2BfVGRAREYmlrNFw6syhnkU3yhkQERFJcAoGREREEpyCARERkQSnYEBERCTBKRgQERFJcAoGREREEpyCARERkQSnYEBERCTBqeiQiEReR4U1d6NZWnX8JLPQiogMSwoGRCQy3I3w/Gp4flXw2utzlph93oeg9rqIBKfeBCIyeFvL4eeLoLqq/3Pzis0+7TFszyoifVPOgIgMzguPwO2zQwsEwDzv9tmw+dHozktEQqZgQEQGbms53L8E/P7wrvP74b7F5vUiMuQUDIjIwLgb4eeLeOBTP1PehORyuOi97qe80wDT/w8yX4EJW+A3+7oc9PvNRwvuxljOWkQCUDAgIgPz/GqorqIwGX40AZaM7X64zgvnvQuXFcDhGbD+C/Ddj2HL4S4nVVfBC2tiOm0R6U3BgIgMzPOrAJibDxflwSh798N/r4NkK1x3DCRZ4EsumJsHq/f2GOe5h2MyXREJTsGAiISv7mDg7YNd+IGee5X8BnzQ1OPEqu1Qfyii0xOR8CgYEJHw7fqg31O+7ILmdnigCrx+eL0Ofl8NDb4AJ3/yfsSnKCKhUzAgIuELIekv1wHPngpP7IeCv8Gt/4KrCiHXHuDklp7LBSISS6pAKCLhC7GC4BlZ8PepR7+e/wF8NTvAianpEZmWiAyMggERCd/4SZ2f+vzgM8wPvwGt7WC1gMMK7zbAienm649/Dn85DO9+KcB4E06J3dxFpBcFAyISvqzRZq+Bqu2s2AXLPzl6KPUV893/X6bALz8z8wR8BnzFBa+cBoUpPcYqLgPXqJhOX0S6U28CERmYp++Dh5YOfpzr7oO5Nw1+HBEZMCUQisjAzFlsNh0ajLxiOHdRZOYjIgOmYEBEBsaZYXYftA7w14jVal6vdsYiQ07BgIgM3ORZcNOq8AMCqxVuXq02xiLDhIIBERmcc6+GuzaH/sggr9g8f/ZV0Z2XiIRMCYQiEhnuRrPp0HMPBy5VXFwG511j5gjo0YDIsKJgQEQir+6gWbK4pcksKDThFG0fFBnGVGdARCIvazScOnOoZyEiIVLOgIiISIJTMCAiIpLgFAyIiIgkOAUDIiIiCU7BgIiISIJTMCAiIpLgFAyIiIgkOAUDIiIiCU7BgIiISIJTMCAiIpLgFAyIiIgkOAUDIiIiCU7BgIiISIJTMCAiIpLgFAyIiIgkONtQT0AGztdag6duB35vM1Z7Go6sidhScod6WiIiEmcUDMQZv7eJ+sqNNFRswNNQ0eu4I7OUzNIFuErmY7WnD8EMRUQk3lgMwzD6O6mhoQGXy0V9fT2ZmZmxmJcE4N6/hQNvLsPn3tfvuTZnIfnTVuIsmB6DmYmISDxTzkCcqK/cxN5XrwgpEADwufex99UrqK98MsozExGReKdgIA6492+h+u3bwPCHd6Hhp/rtW3Hv3xKdiYmIyIignIFhzu9t4sCby/B42lm+toY3PmzlcGM7edlJLLnAxSVfywBg2642Vvymlo+rPGRnJPHdi7P45r+lg+HnwJvLGHf+ZuUQiIhIQAoGhrn6yo343PvwtRvkZSex9rZ8jsmz8X5FG4vvraYgx8akEgdL7j3A9y7OYt4dBWz7xMNV9+znmDwbU05IwefeR33lJrInXj3UP46IiAxDekwwzDVUbADAmWLlxkuyKc63Y7FY+OJxKXzpxBTe2dnK1n+14bBbWDgrkySrhVNKkznn9DSefLWxyzjrh+pHEBGRYU7BwDDma60JuH0QoM3j54PKNk44xoHhh557QvyGwcefeTu/9jRU0N5aG83piohInFIwMIx56nYEfN0wDH64uoZjC+ycc7qTLx6XTEubwWMvNuD1GbzzcSsv/Z+bppbuCYdtddtjMW0REYkzyhkYxvze5l6vGYbBTx+t5ZPPvay7rQCr1UJ2RhK//s887l1/mP/3dB0lRXYu/mo671W0dR/P13s8ERERBQPDmNWe1u1rwzBYvraW9yvbWHd7PhnOows7p52Qwsafjun8+sZfVjN1Ykr38WzdxxMREQE9JhjWHFkTu329fG0t7+xs5dFb83GlJXU79tGnbXi8Bq0ePxtfaeTt7a1cMad7tcjkrLKoz1lEROKPVgaGMVtKLo7MUjwNFew96OOJ8kYcdphx457Ocy48I407F43iN5sbeekfzbS3w6nHJfObHxaQn330f68js5SklJyh+DFERGSYU2+CYe7wjjUc2rpi0OOMmnyH6gyIiEhAekwwzLlK5mNzFg5qDJuzEFfJvAjNSERERhoFA8Oc1Z5O/rSVYBng/yqLlfxpK1WKWMLma63Bvf91mj57Eff+1/G11gz1lEQkSpQzEAecBdPJm3p3+M2KLFbypt6jNsYSMr+3ifrKjTRUbAhY8MqRWUpm6QJcJfMVYIqMIMoZiCPu/Vs48OaykNoY25yF5E9bqUBAQqa/XyKJS8FAnDHfuW2ioWJ9H+/cFuIqmad3bhKy+spNA155cpVcGr2JiUhMKBiIY77WGjx1O/D7mrHa0kjOKtP2QQmbe/8W9r56RXiBQAeLlaIZ67RCIBLnFAyIJDC/t4ndf56Nz72PO9fVUP4PN41uP2mpVuZ8yckPFubgsFn47v3VbP1XG+5WP9kZSVzy1XSu/2YWYD4yGHf+Zq1EicQxJRCKJLD6yo2dOQLfmpXB9+dn40yxUtvYzo2/OMjqZ+u5/ptZ3DA3i/Fj7DjsFvYd8rFo5QGKRtv4xvR0fO591FduUh0LkTimrYUiCayhYkPn56VFDpwpR34lGOZu1k8PmG2wTyh24LBbALBYwGqFT/d7u4yzPnaTFpGI08qASILytdb0SkJ96I91/OqZetxtBlnpVn6wIL/z2E8freF3f2ui1WNQNCqJuWcefSzgaaigvbVWOSsicUrBgEiC8tTt6PXatRdmce2FWVTs9fDs682Mdh1tiPXTq3L58RU5fPiph1e2unGldV9YbKvbjrPgjKjPW0QiT48JRBKU39sc9FhpkYOJ4xwse+hQt9etVgtfmJBMWoqVe5443H08X/DxRGR408qASIKy2tP6PO7zGezukhfQlbe99zGr7eh4NW7YfgiavZBmh7JRkOsc+FwjPZ6IdKdgQCRBObImdn7e3OrnhbeaOXuKkwynlZ2feXnwmXqmT0pl70Ef23a1MX1SKqkOC+9VtPHY5gYun919m7HXWcbqrbD+Q6io7f39SnNg4Umw4GRId/Q/vyYPbNgWufFEJDjVGRBJYLv/dDaehgrcrX6uv6+ajz714PEa5GQmMXuqk+9dnEVtg5/v/+ogOz/z4PdDXnYSF01P59oLXVit5g6DD2yX8j9N97K3sf/vWZQB986C6cXBz9lSBbeUE7HxRKRvCgZEEtjhHWs4tHXFoMZ4vuVS7mu6B38YKUhWC6ycCfNO6n1s44dw68vg7/c3U2jjiUj/lEAoksBcJfOxOQsHfP07njO4r+nusAIBMG/0y142VwC62lIVfiDQ13giEhqtDIgkuIH2JnD701h8eDMHPKOofeoGWneW428+RJKriMyzbiF9mlmR8OCjl9C263WMtmasabmkT1uE65wfAeYS/4uXmc/8mzxwzuOw53Bbn+Md+H9fo+3TN7Ak2TvnMuaHO7G5CruNJyKhUwKhSIJzFkwnb+rdYXctfK5tAdX+Ioz2ZpIyx5B3fTm23Al4dr9F9UNzSMoaS+rEc3DN/gn2vOOx2JLxHa6i+tfnYss5lrQpl7G30XwssOhUM1lwbyMY7b4+xwPI+vpKMr92U685dR1PREKnxwQigqtkHkUz1oX8yMDmLOQl61IArMlpZJ13J/ZRJVgsFpKPnUbKcTNo+2QLAI7CL2CxJR+50oLFYsV78F+dYz2xzfxz/YeENF5/OsYTkdApGBARwFwhGHf+ZkZNvgNHZmnAcxyZpYyafAfpZ22msiHwRn/D24pn99s4Cid1vlb75PV89gMn+5YX429rIn3qlZ3HKmqPfoQ6XsNLK9hzew6f//epNL39m27nV9RCbUuIP7SIAHpMICJdWO3pZE+8muyJV5u9C+p24Pc1Y7WlkZxV1tl7IFiinmEY1GxYjG30caROmtv5es6lD5J98QN49mylZdsfsaZmd7uu/JPQx8u64G7sBSdicThp3fkKh9bNw5qSgXPSNzuv++igthqKhEMrAyISkC0lF2fBGaSPPQdnwRndmhA1ByhMaBgGh5+8Hl/1x4xe9AwWa/dfLxarleTiKVhTMjj8x+93O1bfFvp4yeO/jDXVhSXJTmrZbNK/ci3udzd2u9YduHBiQvK11uDe/zpNn72Ie//r+FprhnpKMgxpZUBEwpZm7/61YRgcfuo7tFW9Rf71L2NNdQW91mj34uuSMwDgSu5xThjjWSy939M47QFOTCB+bxP1lRtpqNjQqzMlmI97MksX4CqZj9WeHmAESTRaGRCRsJWN6v714advoG3X6+R9+yWszqOPAHy1u3G//zT+tiYMv5+2XX+n8W+/JGXi7G7Xz5oQ2nh+dx0tHz2H3+PG8LfTuvNlGl//Nc5TLu52/YmjI/NzxiP3/i3s/vNsDm1dETAQALPl9KGtK9j959m494eWmCkjm+oMiMiAzHzMTNbz1e5m353Hgi0Zi/XoYmPalMvInHUbNY9fhmffP8Hwk+QqJG3K5WTOuq1z2b80B16+PLTxXOf9jIMPX4D3wHYAbDnHkvHVmzprEHQdLxHVV24Ke4soFit5U+/BVXJp9CYmw56CAREZkNVb4WevDX6cH59p1gWI9HiJZqDFowCwWCmasQ5nwfTIT0zigoIBERmQjoqBoTQTCiZQBcJIjZdI/N4mc8m/fi/L19bwxoetHG5sJy87iSUXuLjkaxnU1Ldz1+O1vL29laYWP8X5dr53cRYzTzO3iNqchYw7f7NyCBKUcgZEEl3dQXj3ZXj9GfPPuoMhXZbuMLsFHmlcGDarxby+48Yd6fESSX3lRnzuffjaDfKyk1h7Wz5bVxez8tpR3PPbw2z5oIXmNj8nHuvgyeVjeGdVMTdeksXS/z1IxR4PAD73PuorNw3xTyJDRSsDIonI3QjPr4bnV0HV9t7Hi8tgzhKYsxicGX0OFekug+paGL6OVtSBfOe+ao4/xs6Nl2T3OnbRD/dx2dkZXPI18/+xI7OUcRe8FNW5yvCklQGRRLO1HK45GR5aGjgQAPP1h5aa520t73O4+SfBYxeZS/ShKMowzw924470eCOdr7UmaCDQ5vHzQWUbJxzTe7mkpr6dyr1eTig+eszTUEF7a5BSkDKiKRgQSSQvPAK3z4bqEHv9VleZ529+tM/Tphebz+p/fKaZzR9IaY55/MXL+q8OGOnxRjJP3Y6ArxuGwQ9X13BsgZ1zTu9eOtrjM7j5gYPMmebkCxO6F3loqwsSIMqIpqJDIoliazncvwT8YWab+/1w32IYfQxMnhX0tHSHmcW/6FSoccP2Q2YlQKfd3Pefkxret430eCOV39vc6zXDMPjpo7V88rmXdbcVYO2SiOHxGXzvF9WkOCysWDyq17V+X+/xZORTMCCSCNyN8PNFtPn83LADymvgkBeKkuGWY+HqIvO0OyrgmYOwvRluOAbuP+HI9X4//HwRPLyt3xwCgFxnZN+tR3q8kcRqT+v2tWEYLF9by/uVbay7PZ8M59EFYI/P4MZfVOP1GfxqaT4OW+9sTastrddrMvLpMYFIInh+NVRX4TNgjAPKT4OGGbD2JPjPnfDikXL1pU649zi4MFAFv+oqeGFNTKct/XNkTez29fK1tbyzs5VHb83HlZbU+brXZ3DjL6txtxk8eHMeDnvgbRvJWWVRna8MT9pNIJIIFp8YNFlw7vtwchrc2aVr8ZXbIMveZWWgQ3EZrP4oevOUAenYTbD3oI8ZN+3BYQdbl0cDF56RxgVfSeeyFftJtltI6vI28NpvuPj2N7IA7SZIZHpMIDLS1R0MGgi0tsPb9fCtghDHqtoO9YfA1ftZswydzNIFHNq6gqLRNnb+9tig5/V1zBxnYWQnJnFDjwlERrpdHwR82TBg8UdwnBPm5oUx3ifvR2ZeEjGukvnYnIWDGsPmLMRVMi9CM5KQDbDoV6RpZUBkpHP3ru9rGHD9DvjYDeWTw6z619IUublJRFjt6eRPWzmo3gT501aqFHGsRLDoV6RoZUBkpOvxy8Qw4Ds74K16eHEyuOxhjpeqG8Zw5CyYTt7Uu8ES5q/1I10L1aQoRiJc9CtSFAyIjHTjJ3X78oYd8HodvDQZsnsEAl6/mUfQDrQb5ufenm80J5wSzdnKILhK5lE0Y13IjwxszkKKZqxT++JYiVLRr0jQbgKRRHBkN8HuFjh2CyRboesW88sK4NcnmrsI1n3e/dIrxsDak498od0EccHvbaK+chMNFesDlip2ZJaSWboQV8k8PRqIla3l5o093KJfAFYr3LW5z6Jfg6VgQCQRPH2fuew4WNfdB3NvGvw4EjO+1ho8dTvw+5qx2tJIziojKSVIjWeJDnejueTfY0WgzU+fRcC6ySsOuejXQOgxgUgimLPY/GUyGHnFcO6iyMxHYsaWkouz4AzSx56Ds+AMBQJD4UjRr576KwLWTZSLfikYEEkEzgxYusZcbhwIq9W8PkaZzSIjyvOrAr6clmQW+ypxgsUC07JgRg5sORxknOcejtoUFQyIJIrJs+CmVeEHBFYr3Lw6qs8rRUasPop+9dRRBGxSsJi7o+hXFCgYEEkk515tJiKF+sggr9g8f/ZV0Z2XyEgVpOhXTyEXAYtS0S8FAyKJZvIsMxHpuvvM3QGBFJeZxx/ephUBkcEIUPSrp65FwJ45pZ8iYFEq+qUKhCKJyJlh7gqYe5O5jLnrA/OXTGq6WUdAvQdEIqOfPJuuRcBePi2EImBRKvqlYEAk0WWNhlNnDvUsREamHkW/euooAvbKab2LgAUUpaJfCgZERESiJWu0+dgtQBLh7hZ4cI9ZBGzclqOvdxQB66W4LGqrdgoGREREomnOkoBFv8algnF2GOOcd03k5tSDEghFRESiKQ6KfikYEBERiaY4KPqlYEBERCTahnnRLwUDIiIisTCMi36pa6GIiEgsuRvNpkPPPRy4VHFxmZkseO6imPUDUTAgIiIyVIZJ0S9tLRQRkWHF11qDp24Hfm8zVnsajqyJ2FJyh3pa0TFMin4pGBARkSHn9zZRX7mRhooNeBoqeh13ZJaSWboAV8l8rPbolORNZHpMICIiQ8q9fwsH3lyGz72v33NtzkLyp63EWTA9BjNLHAoGRERkQCKxnF9fuYnqt28Dwx/6RRYreVPvwVVyaZgzlmD0mEBEREIWyeV89/4t4QcCAIaf6rdvxZ42RisEEaKVARERCUkkl/P93iZ2/3l2wLH21/pYvraGdz5uA+DLJ6XwkytzyclM6vU9xp2/WTkEEaCiQyIi0q/6yk3sffWKkAIBAJ97H3tfvYL6yieDjLcx6FjL19YA8OovxvLK/WNp8xr87De1Ab9HfeWmEH8C6YuCARER6dNgl/Pd+7f0OtRQsSHoZXuqfZz3pTTSUqykp1o5b1oaOz/zBDy3oWJ9eHOSgBQMiIhIUH5vEwfeXMZjm+uY+6N9nHTFp3z75wcCnnuovp3Tr6niwtv2Hn3R8HPgzWX4vU2dL/laawLmG3S4ak4mz7/tptHtp6G5nT/9vZkZpzoDnutpqKC9tfeqgYRHwYCIiATVsZyfl53Ety9yMW9G8PK4d66toexYR6/Xey7ne+p29Pk9J5+QQm19O1OuqeL0az+jodnPdRe6gp7fVhegpK+ERcGAiIgE1bGcP/v0NM6ekkZ2RuDbRvk/3NQ1+7nojLQg4xxdzvd7m4N+P7/f4Kq79zP5+GTeW1PMe2uKmXx8Mlfdsz/4Nb7g40loFAyIiEhA/S3nd2h0+7n7t7XceXXwGgNdl/Ot9sABA0Bds5+9h9r5j9mZpCZbSU22cvnsTN6v9FDb2B7wGqst+HgSGgUDIkKNG7ZUweZK888a91DPSIaD/pbzO9y7vpa5Z6ZzbIG9z/M6lvMdWRODnpOTkcS4fBuPv9RIm8dPm8fP4y81UJCTRE5GUsBrkrPKQpqnBKeiQxJfOjp8uRvN1p7jJ5mNPiRsTR7YsA3WfwgVAfKvSnNg4Umw4GRI7/0YWBJAX8v5Hf5vRytbd7bx+//qv/Jgx3K+LSUXR2Zp0FWHXy3N467Ha/m37+7B74cTj3Xw6//MC3iuI7OUpJScfr+39E3BgAx/7kZ4fjU8vyp47+85S2DO4pj1/o53W6rglnLY2xj8nIpa+Nlr8Mh7cO8smF4cs+nJMNHXcn6HNz5s4bNqH9O/8xkAXp9Bq8dg6rVV/OmeQvKyj95mui7nZ5Yu4NDWFQHHLB3r4JFbC0KaY2bpwpDOk76pAqEMb1vL4eeLoLqq/3PzimHpGpg8K/rzimMbP4RbXwZ/v//yj7JaYOVMmHdS9OYlw4+vtYZdv5tift5u0N5u8OAz9Xz8mYdffHc0FqsFj8egqeVo/YHn327myVebeGRZPqOzk0iyWjqPTZj7Tue7+L4qEIZKFQgjRzkDMny98AjcPju0QADM826fDZsfje684tiWqvADATDPX/ayeb0kjo7lfIAHn6njC1dV8as/1PPK1ha+cFUVV9+zn3SnlYJcW+eHy2nFlgQFubZugUDP5XyrPZ38aSvBMsDbkMVK/rSVCgQiRCsDMjxtLTdv7P4wK54BWK1w12atEPTQ5IFzHoc9h9uofeoGWneW428+RJKriMyzbiF92tUAePd/RO3T38WzZysWWzKpJ19I9jfvx+pwUpQBL16mHIJEcnjHmqDL+eEYNfkOside3et1dS0cHrQykGB8rTW4979O02cv4t7/Or7WmqGeUm/uRvPRgN/PA1Uw5U1ILoeL3ut+2h0V8IU3wFYON33c5YDfb17v7uOBeALasM3METDafSRljiHv+nLG3tNA7rfWcvgP/0nLjhcBOPSbb2HPO4GxPzvAmGX/xLv3fRo2/wwwr9/44VD+FBJrrpL52JyFgxrD5izEVTIvyPjzKJqxLuTvYXMWUjRjnQKBCFMCYQKIZMvRmHh+deejgcJk+NEEKK+FPa3dTyt1wr3Hwaq9AcaoroIX1sDcm6I+3Xix/shN3JqcRtZ5d3a+nnzsNFKOm0HbJ1tInXgOvppPyLn0QSw2B0npo0k9+ULaPn2j8/wntsGiU2M9exkqHcv5e1+9IvzeBBDScr6zYDrjzt9MfeUmGirW9/F7aiGuknnD4/fUCKNgYIQLpeWop6GCQ1tXULfjkT5bjsbM86s6P52bb/75XmPvYOCKI28kNgYrTPbcw4kXDATZelnjDrx9EMDwtuLZ/TZpk78FQOaM79P8f7/BXnQqRms9Lf/8PWnTlnSeX1ELtS2QkxqLH0iGA2fBdPKm3j3g5fxQfqdY7elkT7ya7IlXm8WO6nbg9zVjtaWRnFWm7YNRpmBgBAv3WVxHy9EhfRZXdzDw9sGBqNoO9YfANSoy4w1XIWy93D7jTuCSXocMw6Bmw2Jso48jddJcAFJOnEPtE1ex59YM8LeT+oWLOvMJOnx0UFsNE42rZB72tMJ+31x0sDkLB/zmwpaSi63gjIFMUwZIOQMjVDRajsbErg8iO94n70d2vOFmazlcczI8tDR4EFW1neYXHu/1smEYHH7yenzVHzN60TNYrFb87sNUPziLtC8v4Zh73Yy9qxaLI42axy7rdq3bG40fxhQXeS0JqmM5f9TkOzp3GfTkyCxl1OQ7GHf+5qFfZZSQaWVgBOpoOYrh5851NZT/w2wFmpZqZc6XnPxgYQ4Om4Umt58fP1LDq++6SXFYuOycTL7zzazOlqNDsn830kl/LU39nxOvXngE7l8S0o6LNF/3/66GYXD4qe/QVvUW+de/jDXV7AjnPVSJ4W0h48zvYbFYsNgcpH/lWg4+NKfb9c6+q86GLe7yWhKYlvNHJq0MjEAdLUcBvjUrgxf+u4h314zjj3cXsmO3l9XP1gNw529qqG9u56+/HMsTPx7Dplcb+f1r5s2zZ8vRmIl0BcHUEXrj2FoeciAAUNbYfcXl8NM30LbrdfK+/RJWZ3bn6/b8iViT02na8iBGuw9/ayNNb6zCMbZ7xuCJEawA7d6/hd1/ns2hrSuClqftyGvZ/efZQ7dqJb3YUnJxFpxB+thzcBacoUAgjikYGIE6Wo4ClBY5cKYc+d9smPU9Pj3gpaXNz5/faOamS7PJTEti/Bg7l5+TyVN/aewyzvqeQ0ff+EndvvT5obUdfIZZ+Ka1HTxH7n/eI8fagfYjx7w9740TTonJtGOqy9bLrtJf6f5hL4dJRzYB5HoOUdr4EQC+2t00bXkQb/XH7Fs+js9uSeezW9Kp3XQd1uR0Ri9+FvfW9ez54Sj23XksRksdud9a1/l9SnMilzxYX7mJva9eEXIVuo68lvrKJyMzAREB9JhgxAnUcvShP9bxq2fqcbcZZKVb+cGCfHZ97sXrg7JxR6vHlI1z8Os/1Hd+3dFyNKbRftZos9fAkeffK3bB8k+OHk59Bb6aDX+ZAks+gnWfHz32wGdwxRhYe/KRF4rLRmbyYJetl101ndX960lvwIIu5d0XfraKn514H7accRTfH7zWWPKEM8i/Mfi772+dHPRQWAab12JPG6Nn0iIRopWBESZQy9FrL8zivUfG8dy9hSycmcFoVxLNrQbOZAu2pKPlQjOcVppbu/9i7mg5GlNzjm5j+2kJGGd3//iLWSqdtSf3Pra2643qvGtiO+9Y6bL1Mpi36+GjZrhyzNHXFlStpsi9e1DfuigD5kegP0HXvJaeqg54WbTyAFOWVDH9hs9Y9Wx97wGO5LX4vSM4J0QkhhQMjDB9tRwtLXIwcZyDZQ8dIi3FQovHwNd+9B1iY4uftJTufyU6Wo7G1JzFZtOhwcgrhnMXRWY+w0mIWy/X7IU5uVCYcvS19PYm7v1gEVajfUDf2moxuxdGohRx17yWrtr9Btf9TzUnjXfwxq+O4Te3F/D4Sw08+3rvm/6Q5bWIjEAKBkaY/lqO+nwGu/d7GT/Gji0JdlR5Oo/t2O3h+GO6p4l3bTkaM84Ms/ugdYB/Pa1W8/qR2M44hK2Xze2w4QAsLup9bHrNy9zzwZKwA4KOroWRqi3QNa+lq137vOz63MsNc7Ow2yxMKLRzyVcz2Phq4F0mQ5LXIjICKRgYYRxZEzs/b2718/RfG2lobscwDD6u8vDgM/VMn5RKarKV86alcf+TdTS6/Xy638tjmxu4dEb3G2hyVlmsfwTT5Flw06rwAwKrFW5ePXKbFIWw9fLJA+C0wvlB0iXm73mUx96aHfIjg6IMeOyiyLUvDpTX0qGzm6LR9TWDj6sCFzboyGsJS91BePdleP0Z88+6g+FdLzICKYFwhOloOeppqMACPPv3ZlY+cRiP1yAnM4nZU5187+IsAH5yRS53PFLDmd/9jGSHhcvOzuSb/3Z0K17PlqMxd+7V5nL/zxeF1sY4r9hcERipgQCEtNqxeq9ZqtnWRxw1veZlXvzbyWy8/h2eqDs+YKni0hwzWXD+SZHtUhgor6XD+DF2ikbb+MVTh7nxkmx2H/Dy9F+baGoJnmTYVrcdZ3/V6kKo0sicJeYjqpG4oiTSD7UwHoGi3XI05tyNZtOh5x4O/ov8vGvMHIGR/ou87iDMywt6+ONmKPs7fPwVOO7IE54axyi2Z0yi2ZZBmq+RssYPyPUcMg8+eRBco6hxw/ZDZmVBp92sIxCt3gNNn73I569dG/T4v/Z4uOuxWj781ENBThIzT3Oy4eVG3vhV4GcUY858iPSx5wT/hlvLFVCK9EMrAyOQq2Q+dTseCXnvdiB9tRyNOWeG2XBo7k1HG/G0NJkFhSacMjK3DwbTY+tlT2v2wr9lwZjMdFYXL2b9MUuoyDix13mljR+xsPGPLEgdRTqQ64xdr4H+8lqOG+vg0duO7on87/W1TC1LCXp+n3ktYVRpBMyA4fbZ5qOm2VeFdo3ICKCVgRHKvX/LoFqOFs1Ypz3cw9XT95m9CILYkjuTWyatYa9zXL9DFWWYOwRi2XTI11rDrt9NCXp8R5WH4jwbNpuFV9918+M1Nay7vYCJxYGfVUyY+07gx1lby80be6iBQFdWK9y1WSsEkjAUDERTkHaysRJu10Kgs+XokHUtHKEOen180NpCY7ufjCQrk1JSGW0f4MKcu9FsThRg2Xvj2Ku4ddIq/JakkIfr2CkQqQTBUOz+09lBkwjv23SY9S830uY1mFjs4JaF2Zx2QuCVAUdmKeMueKn3gSP/jR74RxVr98E/m2DOKHjmi+bhqhY48Y3ul7T64bxc+GNH5eW8Ynh428h/9CSCgoHIG2aJSu79W2LSclR6a2xvZ3VNLatqatne2tbreFlKMktyc1icm0NGUug3byDgu94tuTO5/EubwwoEOlgt5o6BWK0QRD2v5cjqye8OmD9beS3saT0aDPTk8UPh3+CXJ8C3uhRq4rr7zMdTIiOcgoFIGqaJSmZHuE00VKzvoyPcQlwl89QRLkLKGxpZVLWHKm//vX6L7XbWFI9lVmaYwWGX5+FNSemcc+Y29jgKqH3qBlp3luNvPkSSq4jMs24hfVr3G2Z74wE+v7uMpKxixtzyHmA+MnjxssjuHAjG721i959nDzqvJWhnzcUndgvGf1oJ7zUGDwY27YfrtsO+MyGlayxVXAarPxrwHEXihRIII2UYJyqp5WhsPVJTy5KqPYT6cKbK62V25S5WF4/lqtww/l902Xq5IW0ue53jMNqaScocQ9715dhyJ+DZ/RbVD80hKWssqROPZtzXPnUD9qJT8TfXdL62txE2fgiLTg30zSLLak8nf9rKQeW15E9bGTgQCLFKY1dr9sG/j+kRCIA5Tv2hxEpSlYSkokOREGY72U5+P9y32Lw+RtRyNLrKGxrDCgQ6+IHFVXsob+i/qFA3k2fBw9tYP+lHAFiT08g6707so0qwWCwkHzuNlONm0PbJ0cZD7n/+Ab+7lrQpl/ca7oltYU58EJwF08mberfZSjMcR/Jagj7OCqFKY1e7W6C8JnDFRgA+eT+8+YnEIQUDgxWknewDVTDlTUguh4ve6+N6v9+8PoTKcjK8Nba3s2gAgUAHP7Coag+N7eGVCq4hgwpfbsBjhrcVz+63cRSaraH9LfXUPbOUnHm/Dnh+RS3UtoT17QfFVTKPohnrsDkLQzrf5iykaMa6vhNcw/y39Og+ODUDTgn2lKZFzZBk5FMwMFhB2skWJsOPJsCSsSGMUV1lFtWRuLa6prbvHIHWVrjwAjgzeIJmldfLmprwyutuPxT4dcMwqNmwGNvo40idNBeAuj/eQtrUK7GPPi7oeB/FuDqvs2A6487fzKjJd+DILA14jiOzlFGT72Dc+Zv7T3ANIzHXb5jBQNBVATDrWYiMcMoZGKwg7WTn5pt/vtdoZjH367mHlbUc51b1dxP/1YMwZgzU1fV52sM1tdyUF/oW1OYA8YdhGBx+8np81R+Td305FquV1srXaNv1OgXf39rneO7+cx4jLqJ5LeMndX7q84PPMD/8BrS2m7sLHEfeBr1UA4c8sLAgyFhgFrYSGeEUDAzGABKVglKiUlw76PUF3D7Y6aOP4I3X4eb/hGW39DnW9tY2Dvl8jLKF9s8zrXujSTMQeOo7tFW9Rf71L2NNdQHQuvNlfDWfsPcn5pK84WvD8Law54ejGHPLP0lymXvqnD3GizVbSi62/noN9KVLlcYVu2D5J0cPpb4CX82GvxypebRmH1ySD65gP3Nxmf5NSkJQMDAYYSYq9euT9+HUmZEdU2Lig9Y+HrT7fLBiOSy7PeTM+fdbWpiZEdpyd1mPe9Xhp2+gbdfr5H3nFazO7M7XM2csJf3Lizu/dr/3JM1vrmb0dZuxZhztd3Bi7OpiRc+cJfDQUn5aAj8tCX7apknBjwFmzwuRBKBgYDAinfSnRKW41djex03+N+vghIlw2mnwj/8LabymvsbrIddpdhisqAVf7W6atjwItmT2LT9ajjhtymXkzPs11pSjdUKsqdlgtWPLOprYUpoTvQZFMTVnMfz+/tBqfgSTV2w2vxJJAAoGBiPSFQSVqBS3MpKC5OJWVcFTT8L6jWGNlx5svCAWngQ/ew1sOeMovr/fOmLm9/jSlaR/6cpur33r5LC+7fDlzDCLeg2mN8HSNSpFLAlDuwkGY3zwNUaf30xW6pq45Onvd5ISleLWpJQgb6ffexdqa+CbF8JZX4WlN0Fzk/n5P4M/ZjolNby35wtONisIDkZRBsyPYX+CqJs8C25aZd7Yw2G1msXA1KRIEsiQrgx0Zg17m7Ha03BkTcSWEni/9LDURzvZ/hKXelGiUlwbbbdRlpLcO4nw7HPgS9OOfv3B+/Cz5bB+E+QEzpAvS0kOOXmwQ7rD7D54+TNm8Bkuq8W8PhaliGOqS5XG4VYmXGQ4iXkwYNbJ30hDxYY+6uQvwFUyPz7q5B9JVOqpv8SlXpSoFPeW5OawdO/n3V9MTTU/OmRnAxbIzw86zjXhlCTuYnox3DMTbn05vICgo2thLNsYx9SRKo28sMbcwhusgdh515g5Ano0IAkopo2KRmQHvT7ayYZMrVJHhMb2dk7evjOk5kTBFNvtbCs7Pvwuhl1sqYJbys1eA/0pyjBXBEZaINBny+iO1uItTWaezoRTtConCS9mwUB95Saq374tvKYkR2qQ91l6dDgI0E42ZFYr3LVZy5IjRHlDI7Mrdw2oJLEV2FwyPvzuhQE0ecymQ09sM3cZ9FSaYyYLzj9p5DwaiGrLaJERLibBgHv/lkF1JyuasW74rxCE27UQjiYqRblrocRWuF0LwQwEwu5aGKIat1my2O01CwqdOHqEbB/sIiYto0VGsKgHA35vEzufOZsfP7iNNz5s5XBjO3nZSSy5wMUlXzP/MTa5/fz4kRpefddNisPCZedk8p1vZnWO0Wff8uFka7kSlQSAe/dXc/vn+wml5VAScNeYAm4pyOv3XOltuAVfIvEo6gmE9ZUbaWvcR152Emtvy+eYPBvvV7Sx+N5qCnJsTJ+Uyp2/qaG+uZ2//nIsNQ1+rrx7P4WjbHzz38ybv8+9j/rKTWRPvDra0x0cJSoJ5s3pts/3h3xzagdu+3w/o+023ZzCNNiW0cfY7VohECEGKwO7/3R2wF0D37mvmuOPsXPN111MuaaKDT8ZwxcmJAOw+k/1vPqum9/eMabzfEdmKeMueCms7z3klKiUcIZLzsBIEyghMMVq6Tth869/MZtDVe2G9Ay45hq4ZF63UyKRsCkyEkR1ZcDXWhMwEGjz+Pmgso2vfyWNXZ978fqgbNzRLKaycQ5+/Yf6btd4Gipob60Nr3vZUMsarV4DCaSxvZ1FHe9SN6yHZ/8IFf+CM6bDz+8/emJTE9y1Al77GyQnw/wFsORa/MCiqj26OR3RX0Jgvs3GAZ8v8MWvvw53/xesuAtOnQzNzVBT0+u0jpbR4XSJFBmJolqB0FO3o9drhmHww9U1HFtg55zTnTS3GjiTLdiSLJ3nZDitNLf2fm/VVhehDoEiUbC6pvbou9TRo2HxEvjm3N4n3nsP1NfDcy/Amkfh97+DPz0LHL05xVqN29ySuLnS/LPGHfMpdFPe0MjJ23eydO/nQbtBBg0EAH71v7DkWphyOiQlQWYmjB8f8NSHh+C/t8hwE9WVAb+3udvXhmHw00dr+eRzL+tuK8BqtZCWYqHFY+BrNzoDgsYWP2kpveMUv6+512siw8WqrjeVmUcSQz/+GKqrj77e0gKbX4BH10FGpvkxfyE883u44OuAeXOKxTvVJg9s2AbrPwy+/XDhSWap41huPxxIQmA3LW7Y/pG5InPR181VgVMnww+WmUFaD+G2jBYZiaK6MmC1p3V+bhgGy9fW8n5lG4/emk+G0/zW48fYsSXBjipP57k7dns4/pjeDcattrRer4kMBwe9vqDvYLvZ/Sl4vXD8CUdfO+EE+NfOzi87bk7RtKUKznncbG4UKBAA8/WfvWaet2UQNbXCMdCEwG4aGsEw4C+vwoMPwR/+BHY7/Oj2oJe839JHC2qRBBDVYMCRNbHz8+Vra3lnZyuP3pqPK+3o89DUZCvnTUvj/ifraHT7+XS/l8c2N3DpjN5JVMlZZdGcrsiAfdAa4s3E3WKWJ+76LjQjA9zd1+WjeXPa+KHZwyCUCoVgnnf5M7Dpw6hNCeiRczEYziNFFBYuhMJCcDrhuuvN9tEtgZ9/hNMyWmQkiuq6mC0lF0dmKbsqd/BEeSMOO8y4cU/n8QvPSOPORaP4yRW53PFIDWd+9zOSHRYuOzuzc1thB0dmaXwlD0pCaQz1ZuJMhdZW8PmOBgRNTeYNq4to3Zy2VIXfuwDM85e9DIUZ0Std3Jlz0VfyJZg5Fr9ZCwcOQHYO/OAW+NqMo8czMqFgDAEF+bnDbRktMtJE/SFZZukCihpWsPO3xwY9J91p5b4b+n5Gmlm6MMIzE4mcjFBvJuOONYOAnTvhxBPN1z7+GEqP63ZaNG5OTR6zZ4HfgNqnv0vLP5/B31KPNSUD5ymXknXhvVhsDuqeu4OWfz6D98B2MqbfQPbc+wHzulvK4cXLopND0Jlz0ZF8+dab3fMtAJ5+Cn77ONy9Ek6YCLW1Zh5GT3Mvhg0b4CtnQKYLVj0EU7/UK+jqEG7LaJGRJurhsKtkPjZn4aDGsDkLcZXM6/9EkSEyKaXHzcTng7Y2aG83S1S3tZm5AqmpcM5sM9u9sdHcA79hfa9dB9G4OW3YdvTRQMYZ1zPmth0cs7KBgh+8j2ff+zS8ci8AtlGlZH39XlJPvrDXGHsbzccMkdYt52LmLJhxFmRldz+pvR1+/aC5EjCxDCwWyM2FsWN7D3jV1TB1KiyYB+fNNldjfvZfAb/3QFpGi4w0UQ8GrPZ08qetBMsAv5XFSv60lcO/FLEktNF2G2UpyUdfWL0KvjwV1qyCv/3V/Pz668xjy26D9HSYcw5cdQVcdFHnTgKI3s1pfZebuL2gDGtyR0KuARYrvoP/AiB96hWknjgHa3LgAmNPbIv41ELLudj9qVkrYMd2OH8OnHs2/Gy5+Zilp6QkWPp9eOWv5se9/x+MClzwa6Ato0VGkpiEw86C6eRNvXvAXQuHfZMiEWBJbg5L935ufnHdt82PQNLTzWXuIKJxc6px9941UF9+Dw0vrsDwNGNNyyXr68Hn1FVFLdS2RLbZUUg5F/VHCpG99RY8/oT5+W3L4H/+G36yfEDft9huZ5GCAZHorwx0cJXMo2jGupAfGdichRTNWDf82xeLHLE4N4die+8tseGI1s1p+6Her7lm3cox9zYx5taPSP/KdSRlFoQ83kcHIzg5Qsy56Hjef9UiyM42P65aZK68DIAVWFM8VtUeRYhhMADmCsG48zczavIdODJLA57jyCxl1OQ7GHf+Zq0ISFzJSEpiTfHYAf+jiubNqbmPzr72gjIcRadQ88SVIY/n7r9TcFh65VwEMu5Ys3xzBHR0LVQfCBFTzLNmrPZ0sideTfbEq83eBXU78PuasdrSSM4q0/ZBiWuzMjNYVTx2wC11o3VzSutnwcJo93bmDITCObgFkF46ci62t7aZyZft7d2TL61WSEmB886HdY9AWRlYMD/vuq0wBMV2O2sUCIh0M6QptLaUXGwFZwzlFEQi7uojjwsWVe0J3lGvi1jcnMq65M7525pwv/ckzi98E0uqC+/n26h/cQUpE2cDZmCAvx3DOPLhbQVrEpakoxHAiVGoltyZc7F6FTz866MHvjwVTpsCq9bA938A99wNF5wHDjt89WtmomAX+bYkDvjae41flpLMNbk5LMrN0aMBkR6i3sJYJFE1trezpqaWh4N03Yv1zWnmY2byn7+tmUNrLsKzZyuGrw1rRh7OSRfjmrMcq8NJzW+vpPn/1nW7Nu30K8j997WA2bPg5csjP7/G9va+WxKHoKMlcavf4IPWFpra/aQnWTklNVXbB0X6oGBAJAYOen1DfnNavdXsNTBYPz4TFp06+HECKW9oZHblrgGVJLYCm0vGa/lfZABUg1MkBkbbbczMyOAbWS5mZmQMybvUBSdD0SDvk0UZMP+kyMwnkI6ci3B/MSkhUGRwFAyIJIh0B9w7C6yWgV1vtZjXR7ud8dW5OWwuGR/yNs1iu53NJeO5SvUCRAZMjwlEBqLuIOz6ANyN4MyA8ZMgKwpZdVGw8cPwmxVZLbByJsyL4qpAT8Mt50JkJFMwIBIqdyM8vxqeXwVV23sfLy6DOUtgzmIzQBjGtlSZTYdCaWNclGGuCESrW2EohkPOhchIpmBAJBRby+Hni6C6qv9z84ph6RqYPCv68xqEJo+5SvDEtt6lisHcNfCtk80cgWg/GpDwddZp8TZjtafhyJqILSV3qKclcUrBgEh/XngE7l9iFsAJldUKN6+G2VdFb14RVOM2Sxa7vWZBoRNHR7b3gESG39tEfeVGGio24Gmo6HXckVlKZukCXCXz1dxNwqJgQKQvW8vh9tnhBQIdrFa4a/OwXyGQ+ODev4UDby7D597X77k2ZyH501aqpLuETLsJRIJxN8LPF/HAp36mvAnJ5XDRe91PueR9GPNXyHwFxr8GKz7pctDvNx8tuEN4MC/Sh/rKTex99YqQAgEAn3sfe1+9gvrKJ6M8MxkpFAyIBPP8aqiuojAZfjQBloztfcpPJsCn/wYNZ8Ffp8AT++Hxz7ucUF0FL6yJ2ZRl5HHv3xJ++3cAw0/127fi3r8lOhOTEUXBgEgwz68CYG4+XJQHowJse/9CBiQf+VdksZj/oP7l7nHScw9HdZoycvm9TRx4cxmPba5j7o/2cdIVn/Ltnx/odk7FHg//cdd+piyp4ivXV/Gj1YdoaTsSOBh+Dry5DL+3aQhmL/FEwYBIIHUHA28fDOD67eB8GYpfg6Z2uLKwxwlV26H+UOTnKCNefeVGfO595GUn8e2LXMyb0XvL6tL/PciEMXb+/qtj+NM9Reyo8vC/v6/vPO5z76O+clMspy1xSMGASCC7Pgj51AfLoOks+L+p8B9jIDvQ9vdP3o/c3CRhNFRsAGD26WmcPSWN7Izev7I/q/Zx4RlpOGwWcjKTmDnZyc7PPD3GWR+T+Ur8UjAgEkiYSX9WC0xxQYYNvr8zwAktWqaV8PhaawJuH+xp0fkunnmtiVaPn4N1Pl76h5uzJju7neNpqKC9NUAxCZEjVMJLJJABVhD0GgFyBgBStedbQtClzLXH2BPSJWeeksptDx/i1EVVtPth1hQnF3+199+3trrtOAvOiPSMZYRQMCASyPhJnZ/6/OAzzA+/Aa3t5krA523wjwaYnQvOJHizHn5ZBd8LVLZ3wimxm7vElyBlrv3FTjgrr89L65vbufLu/dx4STYLZ2XQ0ubnZ+tq+f6DB/nF97pf6/c1R2X6MjIoGBAJJGu02WugajsrdsHyLvUDUl+Br2bDupPg/ipY9JEZJBQmw3ePgVuP7TFWcRm4RsVy9hIv+ihzbfX2v5Ww6oCPNo/Bf8zOwGKx4LAlMf+sDJbce6DXuVZbWkSmLCOTggGRYOYsgYeW8tMS+GlJ4FNeOz2Ecc67JqLTkhGinzLXjtqjSYC+doP2doP2djAMaPP4sVgtTCi040yx8tuXGlkwM4NWj8GmVxspO7Z3M4nkrLKo/SgS/1SOWIaNjs50je1+MpKsTEpJZbR9CONVdyNcc3JozYmCySuGh7cN+y6GEmMhlrnefVEhniwHv3z6MA/8rr7bsallyTz+ozG883Er/73hMP/a4yHJamHy8cncfnkOxXlHC2M4MksZd8FLUflRZGRQMCBDqrG9ndU1tazqo2f9ktwcFg9Vz3r1JpBI6yPI/O4OeKYa6n3mzpSvlzn47s1jcNgsg/qWoybfQfbEqwc1hoxs2looQ6a8oZGTt+9k6d7PAwYCANtb21i693NO3r6T8oYhqPE/eRbctMq8sYejo2uhAgHp6UiZ60CuHws7zjDLW78/DT6u8vDI04cH9e1szkJcJfMGNYaMfAoGZEg8UlPL7MpdVHm9IZ1f5fUyu3IXj9YMwV7pc6823+HnBdomEEBesXl+nLQvlhg7UuY6kLJ0SDuyAGZg/oLev63JzFAdCIuV/Gkr1c5Y+qVgQGKuvKGRJVV7CHfh3Q8srtozdCsED2+D6+4zdwcEUlxmHn94m1YEJLAQylzfswvSX4G8v8L7jXDzKD95f68JPyCwWMmbeo/aGEtIlDMgMdXY3s7J23f2XhH4yR3w/HNg79IN6MGH4JTe+/OL7Xa2lR0/NDkEHTqKw7Q0mQWFJpyi7YPSv3dfhmWhBYrbm+C3++G6sTA2BdxjUjhwxih86f0n1dqcheRPW6lAQEKmrYUSU6traoM/Grh0Pvzgln7HqPJ6WVNTy015oyM8uzBkjYZTZw7d95f4FEaZ67J0OCUDrvwQyk8D5+etjHtmL/XHZ9BwfDqerN7bBx2ZpWSWLsRVMk+PBiQsCgYkplZF6Jn/w0MdDIgMRJhbTL3+7uWtrT6D7I8ayP6oAV+yFc+yX+A/9nistjSSs8pISsmJ8IQlUSgYkJg56PUF3TUAwJ+fNT9GjYJvXAT/fnnQLP7trW0c8vkYZdNfYYkjXcpc99TkgycPwDfzwGWDbU2wYpdZ7joQW5sf2xcW6PGURIR+k0rMfNDaEvzggm/BTTdDpgs+/BBu/QFYrHDZ5UEveb+lhZkZKuYjcaRLmeueLBZ4Yj98/1/Q5oc8B1ycB8uDVL9UmWuJJAUDEjON7X3sHyjrkqE/aRJceTX86dk+g4GmvsYTGa6OlLnuKS0JXjotjHFU5loiSFsLJWYyksL462btv+JaejjjiQwXcxaHXrMimLxiOHdRZOYjgoIBiaFJKanBD764GZqazC4sH30Ijz4KM/vegnVKah/jiQxXzgxYuib8qpYdrFbzevW7kAhSMCAxM9puoywlOfDBjRvgvHNh+pfhh7fBpfPg8v8IOlZZSrKSByV+qcy1DDP6bSoxtSQ3h6V7P+99YM2jYY1zTa62UEmcO/dqc7n/54tC64yZV2yuCCgQkChQBUKJqaAVCMMwLCoQikSKuxFeWAPPPRy4VHFxmZkseO4iPRqQqFEwIDFX3tDI7MpdYfcmAPO51uaS8czK1C9FGYFU5lqGiIIBGRKP1NSG3azICqwuHstVekQgIhJRSiCUIXF1bg6bS8ZT3LUxUR+K7XY2l4xXICAiEgUKBmTIzMrMYFvZ8dxXNCboLoOylGTuKxrDtrLj9WhARCRK9JhAho2DXh8ftLbQ1O4nPcnKKamp2j4oIhID+k0rw8Zou42Zdr37FxGJNT0mEBERSXAKBkRERBKcggEREZEEp5wBEZE44WutwVO3A7+3Gas9DUfWRGwpuUM9LRkBFAyIiAxjfm8T9ZUbaajYgKehotdxR2YpmaULcJXMx2pPH4IZykigrYUiIsOUe/8WDry5DJ97X7/n2pyF5E9bibNgeujfoKP8sbvR7HswfhJkjR7EjCVeKRgQERmG6is3Uf32bWCEUbTbYiVv6j24Si4Nfo67EZ5fDc+vCt4Yac4SmLNYjZESiIIBEZFhxr1/C3tfvSK8QKCDxUrRjHWBVwi2lqtlsgSkYEBEZBjxe5vY/efZ+Nz7uHNdDeX/cNPo9pOWamXOl5z8YGEOjc1+7nq8lre3t9LU4qc43873Ls5i5mlOwHxkMO78zd1zCF54BO5fAv4wAgyrFW5eDbOvivBPKcONthaKiAwj9ZUbO3MEvjUrgxf+u4h314zjj3cXsmO3l9XP1tPc5ufEYx08uXwM76wq5sZLslj6vwep2OMBwOfeR33lpqODbi0PPxAA8/z7FpvXy4imYEBEZBhpqNjQ+XlpkQNnypFf0wZYrPDpAS/FeXYWne+iINeG1WrhrMlOxo+x815FW5dx1pufuBvNRwN+Pw9UwZQ3IbkcLnrv6Pes9sC//xPG/g0yX4FT34Q/Vh856Peb17sbo/uDy5BSMCAiMkz4Wmt6bR986I91fPHq3Uz79mfs2O3h8nN6P6qtqW+ncq+XE4odna95Gipob601kwWP5AgUJsOPJsCSsd2vb/LBqRnw5lSomwF3lsDCf8JHTUdOqK6CF9ZE9GeV4UXBgIjIMOGp29HrtWsvzOK9R8bx3L2FLJyZwWhXUvdrfAY3P3CQOdOcfGFC91bgbXXbzV0DR8zNh4vyYJS9+/eY4ITvHwtjU8Bqga+PhhPS4M36Lic99/BgfzwZxhQMiIgME35vc9BjpUUOJo5zsOyhQ52veXwG3/tFNSkOCysWj+o9Xv3ngbcP9qPaA9ubYVLXGkZV26H+UNBrJL4pGBARGSas9rQ+j/t8Brv3ewEzELjxF9V4fQYP3JSHw2bpPd7B/WHPweOHBR/AvHyY4upx8JP3wx5P4oOCARGRYcKRNbHz8+ZWP0//tZGG5nYMw+DjKg8PPlPP9EmpeH0GN/6yGnebwYM35+Gw9w4EAJL9WWF9f48fLnkfnEmw6sQAJ7Q0BXhRRgL1JhARGSZsKbk4MkvxNFRgAZ79ezMrnziMx2uQk5nE7KlOvndxFu/+q42X32kh2W7hS9d91nn9td9w8e1vZAFmz4KkjDEhf2+PHy79ADwG/OGL4Aj0VjFVvQ9GKgUDIiLDSGbpAg5tXYEzxcra2woCnjO1LIWdvz22n3EWQsGkbq/5/OAzzA+/Aa3tZsKgBZj3ATS3w5++CMnB1ownnBL2zyPxQY8JRESGEVfJfGzOwkGNYXMW4iqZZzYdKi7rfH3FLkh9Bf5rFzx7yPz8nK3w9zr4w0F4vQ5G/RXSXzE/7trVZdDiMnD1TlKUkUHliEVEhpmI9iZ4+j54aOngJ3XdfTD3psGPI8OSVgZERIYZZ8F08qbebZYcDMeRroXdmhTNWWw2HRqMvGI4d9HgxpBhTcGAiMgw5CqZR9GMdSE/MrA5Cymasa53+2Jnhtl90DrAX/dWq3m92hmPaHpMICIyjPm9TdRXbqKhYn2vUsVg7hrILF2Iq2Re9y6FPalrofRBwYCISJzwtdbgqduB39eM1ZZGclYZSSk5oQ+wtdxsOnSkV0Gf8orNFYHJswY+YYkbCgZERBKJu9FsOvTcw4FLFReXwXnXmDkCejSQMBQMiIgkqrqDsOsDs7JgarpZR0DbBxOSig6JiCSqrNFw6syhnoUMA9pNICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIgrMN9QREREQGy9dag6duB35vM1Z7Go6sidhScod6WnFDwYCIiMQlv7eJ+sqNNFRswNNQ0eu4I7OUzNIFuErmY7WnD8EM44fFMAyjv5MaGhpwuVzU19eTmZkZi3mJiIgE5d6/hQNvLsPn3tfvuTZnIfnTVuIsmB6DmcUn5QyIiEhcqa/cxN5XrwgpEADwufex99UrqK98Msozi18KBkREJG6492+h+u3bwPCHd6Hhp/rtW3Hv3xKdicU55QyIiIwgIzmRzu9t4sCby3hscx2//1sTH3/m4cxTUvnV0vzOcy5b8Tnv/qsNe5Kl87XN/1NEfrYNDD8H3lzGuPM3K4egBwUDIiJxLlES6eorN+Jz7yMvO4lvX+Ti79ta2V/r63XeDxZkc+UcV8AxfO591FduInvi1dGeblzRYwIRkTjm3r+F3X+ezaGtKwIGAgCehgoObV3B7j/Pjutl8oaKDQDMPj2Ns6ekkZ0xsFtYQ8X6SE5rRFAwICISpxIpkc7XWhM02OnpwWfqOf2aKr5x+z5+/1pTr+OehgraW2sjPcW4pscEIiJxaLCJdPa0MXG11c5TtyOk8/5zfjalRQ5SHBbe/KiVG39ZTVqKhXNOT+t2XlvddpwFZ0RjqnFJwYCISJzpSKTzeNpZvraGNz5s5XBjO3nZSSy5wMUlX8voPHfTq42s+XM9+2vbycmw8sPLc5k1xRl3iXR+b3NI5516XErn5/82KZUFZ2Xw3JvNvYIBvy+08RKFggERkTjTkUjnazfIy05i7W35HJNn4/2KNhbfW01Bjo3pk1LZ8Eoja59v4L4bRlM2zkFNgx93m7mSEG+JdFZ7Wv8nBWAJ8jDcahvYeCOVcgZEROJMRyKdM8XKjZdkU5xvx2Kx8MXjUvjSiSm8s7OVdr/BL586zI8uz+HEY5OxWCyMciVRnGfvMk78JNI5siZ2fu5rN2jz+GlvB8OANo8fj8+gobmdv7znpqXNT7vf4O/bWtjwciOzp/a+8SdnlcVy+sOeVgZEROJIX4l0bR4/H1S28fWvpLFrn5dD9X4+/LSNO9YcwtcOZ56Sym3/nkO603wf2JFIl5SSE8sfYUBsKbk4MkvxNFTw4DN1PPC7+s5jX7iqiqllyfzye3k88Ls6bt7rBWDsaBu3/XsOc77UPRhwZJbGxc8cSwoGRETiSLBEOsMw+OHqGo4tsHPO6U62/qsNgL9va+XpFYUA3Pz/DnLX47Xcdc2ozuviKZEus3QBh7au4HsXZ/O9i7MDnvPUnYUhjLMw0lOLe3pMICISRwIl0hmGwU8freWTz708uDQPq9WCM9mswHfthS5yMpLIyUji2gtdvPKuu/t4cZRI5yqZj83Z/82+LzZnIa6SeRGa0cihYEBEJI70TKQzDIPla2t5v7KNR2/NJ+PII4AJhXaS7ZZAQ3QfL44S6az2dPKnrQyeFdgfi5X8aSvjZgdFLCkYEBGJI10T6QCWr63lnZ2tPHprPq60pM7XUxxWLjwjjVXP1lPf3E5Dczurnq1n5mRnt+vjLZHOWTCdvKl3hx8QWKzkTb0nrmorxJLFMAyjv5MaGhpwuVzU19eTmZkZi3mJiEgQu/90Np6GCvYe9DHjpj047GCzHl0FuPCMNO5cNAp3q5/la2sof8eNw2bhrMlObrssh/RU80bqyCxl3AUvDdWPMSju/Vs48OaykKov2pyF5E9bqUCgDwoGRETizOEdazi0dcWgxxk1+Y64qTMQiNmgaRMNFev7aNC0EFfJPD0a6IeCARGROOP3NrH7z7ND7kkQiM1ZGFcVCPvT2brZ14zVlkZyVpm2D4ZBWwtFROJMRyLd3levCL83AYzIRDpbSi62ONkiORwpgVBEJA4pkU4iScGAiEiccpXMo2jGupD33tuchRTNWIer5NIoz0zijXIGRETinBLpZLAUDIiIjCBKpJOBUAKhiMgIokQ6GQjlDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIglMwICIikuAUDIiIiCQ4BQMiIiIJTsGAiIhIgrMN9QQGq8YN2w9BsxfS7FA2CnKdQz0rERGR+BGXwUCTBzZsg/UfQkVt7+OlObDwJFhwMqQ7Yj8/ERGReGIxDMPo76SGhgZcLhf19fVkZmbGYl5BbamCW8phb2P/5xZlwL2zYHpx9OclIiISr+IqZ2Djh3D5M6EFAmCed/kzsOnDaM5KREQkvsVNMLClCm59Gfz9rmN05zdg2cvm9SIiItJbXOQMNHnMRwPt3jZqn7qB1p3l+JsPkeQqIvOsW0ifdjW+w1V8fveJ3a4zfK2klp3H6CV/5JZyePEy5RCIiIj0FBfBwIZt5pK/0e4jKXMMedeXY8udgGf3W1Q/NIekrLGkTjyHY+5t6rzG8HnY+5NCnJMXAOb1Gz+ERacO1U8hIiIyPMXFY4L1R575W5PTyDrvTuyjSrBYLCQfO42U42bQ9smWXte4//kMGH6ck+Z2vvbEthhNWEREJI4M+2Cgxh14+yCA4W3Fs/ttHIWTeh1rfnMNztP+HYs9pfO1ilqobYnWTEVEROLTsA8Gth8K/LphGNRsWIxt9HGkdnn3D+Cr3U3rznLSpy3udd1HB6MxSxERkfg17HMGmr29XzMMg8NPXo+v+mPyri/HYu0e0zS99SiOsafiKDql17XuAOOJiIgksmG/MpBm7/61YRgcfuo7tFW9Rd63X8Sa6up+3O+n+e1HSQuwKgDgtAd8WUREJGEN+5WBslHdvz789A207XqdvO+8gtWZ3ev81o9fwt98iLTJCwOOd+LoaMxSREQkfg37YCDXafYaqKg1cwGatjwItmT2LR/XeU7alMvImfdrAJrfWoPzlEt6rRiAOU5OasymLiIiEhfiojfB6q3ws9cGP86Pz1SdARERkZ6Gfc4AmN0HizIGN0ZRBsw/KTLzERERGUniIhhId5jdB62WgV1vtZjXqxSxiIhIb3ERDIDZhviemeEHBFYLrJypNsYiIiLBxE0wAOYy/2MXhf7IoCjDPH+eHg+IiIgEFRcJhD01ecymQ09sC1yquDQHvnWyGTzo0YCIiEjf4jIY6KrGbZYsdnvNgkInjtb2QRERkXAM+zoD/cl1Kh9ARERkMOIqZ0BEREQiT8GAiIhIglMwICIikuAUDIiIiCS4kBIIOzYcNDQ0RHUyIiIiEnkZGRlYLMGr9oUUDDQ2NgJwzDHHRGZWIiIiEjP9lQYIqc6A3+9n3759/UYWIiIiMvz0d/8OKRgQERGRkUsJhCIiIglOwYCIiEiCUzAgIiKS4BQMiIiIJDgFAyIiIglOwYCIiEiCUzAgIiKS4P5/Fy3Df9eOsdsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('output/example/args.json') as f:\n",
    "    args = json.load(f)\n",
    "# Nodes should start from number '1'\n",
    "A_nx = nx.karate_club_graph()\n",
    "mapping = {node: node + 1 for node in A_nx.nodes()}\n",
    "A_nx = nx.relabel_nodes(A_nx, mapping)\n",
    "embedding_path = train(lrc=True, A_nx=G, dictionary=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_path = 'output\\example\\embed_afterLSTM_50.txt'\n",
    "# Loading embeddings\n",
    "with open(embedding_path) as f:\n",
    "    embeddings = f.readlines()\n",
    "    embeddings = [list(map(float, x.strip().split()[1:])) for x in embeddings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 0, 2, 3, 7, 3, 2, 8, 8, 7, 3, 10, 6, 2, 6, 2, 7, 9, 6, 1, 9, 8, 8, 7, 10, 0, 6, 9, 11, 1, 1, 6, 2, 0, 6, 1, 5, 0, 6, 2, 3, 7, 5, 6, 4, 0, 11, 2, 4, 11, 10, 8, 3, 11, 6, 1, 9, 4, 11, 10, 2, 6, 9, 10, 2, 9, 4, 11, 8, 10, 9, 6, 3, 11, 3, 4, 9, 8, 8, 1, 5, 3, 5, 11, 3, 6, 4, 9, 11, 0, 5, 4, 4, 7, 1, 9, 9, 10, 3, 6, 2, 1, 3, 0, 7, 0, 2, 3, 8, 0, 4, 8, 4, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "# read football.gml and get ground truth for communities\n",
    "# Read the football.gml file\n",
    "G = nx.read_gml('../data/football.gml')\n",
    "\n",
    "# Get the ground truth for communities\n",
    "y_football = [G.nodes[node]['value'] for node in G.nodes()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(y_football))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  9  1  8  4 10  8  2  6  4  2  0  8 10  6  1  4  2  8  4  3  0  6  6\n",
      " 11  2  8  3  5  0  0  4  8  5  8  0  2  9 11  8  6  6  8 10  2  2 11  1\n",
      "  5 11  2  0 10 11  4  4  3  9  9  2  8  4  3  0  1 10  5 11  1  5  3  9\n",
      " 10 11 10 10  3  6  6  4  5  6 10  5  2  6  2  8  9  9  0  5  5  1  6  3\n",
      "  3  3 10  4  4  0  2  9  8  9  4 10 10  2  7  8  3  3 11]\n",
      "0.4665109299141064\n"
     ]
    }
   ],
   "source": [
    "# apply k-means clustering on embeddings\n",
    "kmeans = KMeans(n_clusters=12, random_state=0).fit(embeddings)\n",
    "y_true = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "nmi = normalized_mutual_info_score(y_football, kmeans.labels_)\n",
    "print(kmeans.labels_)\n",
    "print(nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for testing a dataset (a graph after loading) and storing the result(appending) the nmi in a dataframe and saving it\n",
    "def test(graph, y_true, tests_df, args):\n",
    "    embedding_path = train(graph, args)\n",
    "    with open(embedding_path) as f:\n",
    "        embeddings = f.readlines()\n",
    "        embeddings = [list(map(float, x.strip().split()[1:])) for x in embeddings]\n",
    "\n",
    "    # Clustering\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(embeddings)\n",
    "\n",
    "    nmi = normalized_mutual_info_score(y_true, kmeans.labels_)\n",
    "    # Other metrics\n",
    "    # acc = accuracy_score(y_true, kmeans.labels_)\n",
    "    f1 = f1_score(y_true, kmeans.labels_)\n",
    "\n",
    "    tests_df = pd.concat([tests_df, pd.DataFrame({'graph': str(A_nx.edges()), 'y_true': str(y_true), 'y_result': str(list(kmeans.labels_)), 'nmi': str(nmi), 'f1': str(f1)}, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the embeddings\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(*zip(*np.array(embeddings)[:,:2]), c=y_true, s=50, cmap='viridis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
